{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-11 20:30:06.713548: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras.layers import Conv1D, Embedding, GlobalAveragePooling1D \n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model('model_A.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing of image\n",
    "width = 100\n",
    "height = 100\n",
    "X = []\n",
    "\n",
    "path = \"images/image_1.jpg\"\n",
    "img = image.load_img(path,target_size=(width,height,3))\n",
    "img = image.img_to_array(img)\n",
    "img = img/255.0\n",
    "X.append(img)\n",
    "        \n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100, 100, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 169ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model_A.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_translator_dict = {0: \"negative\",\n",
    "                         1: \"neutral\",\n",
    "                         2: \"positive\",\n",
    "                         3: \"very_negative\",\n",
    "                         4: \"very_positive\"}\n",
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 176ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Tuple, Dict\n",
    "\n",
    "def sentiment_detection(sentiment_model: keras.Model, \n",
    "                        path_to_img: str) -> int:\n",
    "    \n",
    "    #image preprocessing:\n",
    "    width = 100\n",
    "    height = 100\n",
    "    X = []\n",
    "    path = path_to_img\n",
    "    img = image.load_img(path,target_size=(width,height,3))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255.0\n",
    "    X.append(img)\n",
    "    X = np.array(X)\n",
    "    \n",
    "    # prediction\n",
    "    model_prediction = sentiment_model.predict(X)\n",
    "    predicted_class = np.argmax(model_prediction)\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "sentiment_detection(model_A, path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_C = keras.models.load_model(\"model_C.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 152ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'humour': 1, 'sarcasm': 1, 'offensive': 0, 'motivational': 0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def all_other_analysis(all_model: keras.Model,\n",
    "                       path_to_img: str,\n",
    "                       helper_dict: Dict[int, str]) -> Dict[str, int]:\n",
    "    #image preprocessing\n",
    "    width = 100\n",
    "    height = 100\n",
    "    X = []\n",
    "    path = path_to_img\n",
    "    img = image.load_img(path,target_size=(width,height,3))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255.0\n",
    "    X.append(img)\n",
    "    X = np.array(X)\n",
    "    \n",
    "    model_prediction = all_model.predict(X)\n",
    "    prediction = {}\n",
    "    for i, mini_pred in enumerate(model_prediction):\n",
    "        pred_class = np.argmax(mini_pred)\n",
    "        prediction[helper_dict[i]] = pred_class\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "dummy_translator_for_modelC_columns = {0: \"humour\",\n",
    "                                       1: \"sarcasm\",\n",
    "                                       2: \"offensive\",\n",
    "                                       3: \"motivational\"}\n",
    "all_other_analysis(model_C, path, dummy_translator_for_modelC_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sentiment': 3, 'humour': 1, 'sarcasm': 1, 'offensive': 0, 'motivational': 0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def meme_prediction(sentiment_model: keras.Model,\n",
    "                    all_model: keras.Model, \n",
    "                    path_to_img: str) -> Dict[str, int]:\n",
    "    \n",
    "    #image preprocessing\n",
    "    width = 100\n",
    "    height = 100\n",
    "    X = []\n",
    "    path = path_to_img\n",
    "    img = image.load_img(path,target_size=(width,height,3))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255.0\n",
    "    X.append(img)\n",
    "    X = np.array(X)\n",
    "    \n",
    "    prediction = {}\n",
    "    \n",
    "    # sentiment\n",
    "    model_prediction = sentiment_model.predict(X)\n",
    "    predicted_sentiment = np.argmax(model_prediction)\n",
    "    # dummy_translator_dict = {0: \"negative\",\n",
    "    #                      1: \"neutral\",\n",
    "    #                      2: \"positive\",\n",
    "    #                      3: \"very_negative\",\n",
    "    #                      4: \"very_positive\"}\n",
    "    dummy_translator_dict = {0: 1,\n",
    "                         1: 2,\n",
    "                         2: 3,\n",
    "                         3: 0,\n",
    "                         4: 4}\n",
    "    prediction[\"sentiment\"] = dummy_translator_dict[predicted_sentiment]\n",
    "    \n",
    "    # all else\n",
    "    helper_dict = {0: \"humour\",\n",
    "                    1: \"sarcasm\",\n",
    "                    2: \"offensive\",\n",
    "                    3: \"motivational\"}\n",
    "    model_prediction = all_model.predict(X)\n",
    "    for i, mini_pred in enumerate(model_prediction):\n",
    "        pred_class = np.argmax(mini_pred)\n",
    "        prediction[helper_dict[i]] = pred_class\n",
    "        \n",
    "    return prediction\n",
    "\n",
    "meme_prediction(sentiment_model=model_A, all_model=model_C, path_to_img=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentiment  humour  sarcasm  offensive  motivational\n",
      "0          3       1        1          0             0\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.DataFrame()\n",
    "\n",
    "test = {'sentiment': 3, 'humour': 1, 'sarcasm': 1, 'offensive': 0, 'motivational': 0}\n",
    "\n",
    "data = pd.DataFrame(test, index=[0])\n",
    "\n",
    "print(pd.concat([test_df, data], ignore_index=True))\n",
    "pd.concat([test_df, data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
